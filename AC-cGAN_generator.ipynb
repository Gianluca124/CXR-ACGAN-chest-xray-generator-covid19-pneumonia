{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "#tf.config.set_per_process_memory_growth(True)\n",
    "\n",
    "import pickle\n",
    "\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, LeakyReLU, Dropout, Flatten, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization, Embedding, Reshape, Activation\n",
    "from keras.layers import Concatenate, Conv2DTranspose, multiply, UpSampling2D\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import Progbar\n",
    "from keras.metrics import *\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and initialize Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(latent_dim = 100, n_classes = 3):\n",
    "    # Initialize RandomNormal with mean = 0.0 and stddev = 0.02\n",
    "    # init = RandomNormal(mean = 0.0, stddev = 0.02)\n",
    "  \n",
    "    ### Input 1: class label input ###\n",
    "    \n",
    "    # Generator take integer class label as input\n",
    "    label_input = Input(shape = (1,))\n",
    "    # print(label_input.shape)\n",
    "    \n",
    "    # Embedding layer: to convert class label integer to a vector of size 100\n",
    "    y = Embedding(n_classes, 100)(label_input)\n",
    "    # print('Embedding Layer: ', y.shape)\n",
    "    \n",
    "    # Dense layer with 7 x 7 units: to convert the vector to a 7 x 7 x 1 tensor\n",
    "    n_nodes = 7 * 7\n",
    "    y = Dense(n_nodes, kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.02))(y)\n",
    "    # print('Dense 1: ', y.shape)\n",
    "    y = Reshape((7, 7 ,1))(y)\n",
    "    print('reshape(final y shape): ', y.shape)\n",
    "\n",
    "    ### Input 2: generator noise input ###\n",
    "    \n",
    "    # A latent_dim-dimensional vector is sampled from a normal distribution\n",
    "    # with mean = 0.0 and stddev = 0.02 \n",
    "    generator_input = Input(shape = (latent_dim,))\n",
    "    \n",
    "    # Noise vector is passed through a dense layer with 1024 * 7 * 7 units \n",
    "    # to produce a 7 x 7 x 1024 tensor\n",
    "    n_nodes = 1024 * 7 * 7\n",
    "    gen = Dense(n_nodes, \n",
    "                kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.02))(generator_input)\n",
    "    gen = Activation('relu')(gen)\n",
    "    gen = Reshape((7, 7, 1024))(gen)\n",
    "    print('Generator noise input: ', gen.shape)\n",
    "    \n",
    "    ### Concatenate both the inputs ###\n",
    "    # The output tensors are then concatenated to produce a 7 × 7 × 1025 tensor. \n",
    "    merge = Concatenate()([gen, y])\n",
    "    print('Concatenate(generator noise input and y: ', merge.shape)\n",
    "\n",
    "    ### Upsampling ###\n",
    "    # four successive transposed convolutions \n",
    "    # to produce tensors with dimensions 14 × 14 × 512, 28 × 28 × 256, 56 × 56 × 128 and 128 × 128 × 3, respectively.\n",
    "    \n",
    "    # (None, 7, 7, 1024) --> (None, 14, 14, 512)\n",
    "    gen = Conv2DTranspose(512, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.02))(merge)\n",
    "    gen = BatchNormalization(momentum = 0.9)(gen)\n",
    "    gen = Activation(\"relu\")(gen)\n",
    "    print(\"(None, 7, 7, 1024) -> (None, 14, 14, 512): \", gen.shape)\n",
    "\n",
    "    # (None, 14, 14, 512)  --> (None, 28, 28, 256)\n",
    "    gen = Conv2DTranspose(256, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.02))(gen)\n",
    "    gen = BatchNormalization(momentum = 0.9)(gen)\n",
    "    gen = Activation(\"relu\")(gen)\n",
    "    print('(None, 14, 14, 512) -> (None, 28, 28, 256): ', gen.shape)\n",
    "\n",
    "    # (None, 28, 28, 256) --> (None, 56, 56, 128)\n",
    "    gen = Conv2DTranspose(128, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.02))(gen)\n",
    "    gen = BatchNormalization(momentum = 0.9)(gen)\n",
    "    gen = Activation(\"relu\")(gen)\n",
    "    print('(None, 28, 28, 256) -> (None, 56, 56, 128): ', gen.shape)\n",
    "\n",
    "    # (None, 56, 56, 128) --> (None, 112, 112, 3)\n",
    "    gen = Conv2DTranspose(3, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.02))(gen)\n",
    "    out_layer = Activation(\"tanh\")(gen)\n",
    "    print(\"(None, 56, 56, 128) -> (None, 112, 112, 3): \", out_layer.shape)\n",
    "    \n",
    "    # The final output from the generator is an fake image X of dimension 112 × 112 × 3\n",
    "    model = Model(inputs = [generator_input, label_input], outputs = out_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_instance = generator(latent_dim = 100, n_classes = 3)\n",
    "generator_instance.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change x with epoch number\n",
    "epoch = 100\n",
    "filename = f\"./AC-cGAN/best_weights/params_generator_epoch_{epoch}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_instance.load_weights(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a batch of noise and label \n",
    "\n",
    "def generate_batch_noise_and_labels(batch_size, latent_dim, gen_class = \"normal\"):\n",
    "    name_map = {'COVID-19':0, 'normal':1, 'pneumonia':2}\n",
    "    # generate a new batch of noise\n",
    "    noise = np.random.uniform(-1, 1, (batch_size, latent_dim))\n",
    "\n",
    "    # defined labels\n",
    "    labels = np.full(batch_size, name_map[gen_class], dtype=int)\n",
    "\n",
    "    return noise, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of images to generate\n",
    "generate_class_n = {'COVID-19':0, 'normal':8405, 'pneumonia':10935}\n",
    "# Batch size\n",
    "batch_size = 256\n",
    "# Path to save images\n",
    "path_save = f'./AC-cGAN/generated_images/epoch_{epoch}'\n",
    "# Class map\n",
    "#class_map = {0:'COVID-19', 1:'normal', 2:'pneumonia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_save}images_list.txt\", \"w+\") as file:\n",
    "    for key, value in generate_class_n.items():\n",
    "        if value != 0:\n",
    "            n_batch = (value // batch_size) + 1 # produce n_batch of images (surplus)\n",
    "            counter_image = 0\n",
    "            for i in range(n_batch):\n",
    "                noise, labels = generate_batch_noise_and_labels(batch_size = batch_size, latent_dim = 100, gen_class = key)\n",
    "                \n",
    "                generated_images_batch = generator_instance.predict([noise, labels.reshape((-1, 1))], verbose=0)\n",
    "                norm_image = cv2.normalize((generated_images_batch + 1) * 127.5, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "                norm_img = norm_image.astype(np.uint8)\n",
    "                for j in range(norm_img.shape[0]):\n",
    "                    cv2.imwrite(f\"{path_save}/{key}/{key}_{counter_image}.png\", norm_img[j,:,:])\n",
    "                    file.write(f\"{key}_{counter_image}.png {key}\\n\")\n",
    "                    counter_image += 1\n",
    "                    print(f\"{key}: {counter_image}/{value}\")\n",
    "              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu-3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e58d6ebb9ee25355625054b7da37cd59d47f033b28e5e9daebb92584e39a5035"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
