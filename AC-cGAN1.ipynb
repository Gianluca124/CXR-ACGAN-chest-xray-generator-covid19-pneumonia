{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and testing Environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 19:56:17.289718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 19:56:17.496117: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "#import shutup; shutup.please()\n",
    "import logging    \n",
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.finfo(np.dtype(\"float32\"))\n",
    "np.finfo(np.dtype(\"float64\"))\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "#tf.config.set_per_process_memory_growth(True)\n",
    "\n",
    "import pickle\n",
    "\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, LeakyReLU, Dropout, Flatten, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization, Embedding, Reshape, Activation\n",
    "from keras.layers import Concatenate, Conv2DTranspose, multiply, UpSampling2D\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import Progbar\n",
    "\n",
    "np.random.seed(16)\n",
    "tf.random.set_seed(16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silencing TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test OpenCV2 Cuda-Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.cuda.getDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.cuda.getCudaEnabledDeviceCount()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test TensorFlow CUDA-Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num CPUs Available:  1\n",
      "Num CPUs Available:  1\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_logical_devices('GPU')))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())\n",
    "# True or False\n",
    "print(tf.test.is_built_with_gpu_support())\n",
    "# True or False\n",
    "print(tf.test.is_built_with_rocm())\n",
    "# True or False\n",
    "print(tf.test.is_built_with_xla())\n",
    "# True or False\n",
    "print(tf.config.list_physical_devices(device_type='GPU'))\n",
    "print(tf.config.list_logical_devices(device_type='GPU'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/giorgio/Projects_Linux/chest-xrays-classification-generation'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26465 images belonging to 3 classes.\n",
      "Found 2939 images belonging to 3 classes.\n",
      "Found 400 images belonging to 3 classes.\n",
      "{'COVID-19': 0, 'normal': 1, 'pneumonia': 2}\n",
      "{'COVID-19': 0, 'normal': 1, 'pneumonia': 2}\n",
      "{'COVID-19': 0, 'normal': 1, 'pneumonia': 2}\n",
      "train_batch.shape: (36, 112, 112, 3)\n",
      "label_batch.shape (36,)\n"
     ]
    }
   ],
   "source": [
    "# set batch size and image size\n",
    "batch_size=36\n",
    "img_size=112\n",
    "\n",
    "# set training, validation, and testing paths\n",
    "training_path = os.path.join(f'./Data/COVIDx-splitted-resized-{img_size}/train')\n",
    "val_path = os.path.join(f'./Data/COVIDx-splitted-resized-{img_size}/val')\n",
    "testing_path = os.path.join(f'./Data/COVIDx-splitted-resized-{img_size}/test')\n",
    "\n",
    "# initialize training data generator with validation split and data augmentation\n",
    "train_datagen = ImageDataGenerator(validation_split = 0.1, shear_range=0.1, zoom_range=0.1)\n",
    "# initialize testing data generator with data augmentation\n",
    "test_datagen = ImageDataGenerator(shear_range=0.1, zoom_range=0.1)\n",
    "\n",
    "# generate training data from training path with batch size and target size specified\n",
    "train_data = train_datagen.flow_from_directory(training_path, subset='training', batch_size = batch_size, target_size = (img_size, img_size),\n",
    "                                               shuffle = True, class_mode = 'binary', seed = 42)\n",
    "\n",
    "# generate validation data from training path with batch size and target size specified\n",
    "val_data = train_datagen.flow_from_directory(training_path, subset='validation', batch_size = batch_size, target_size = (img_size, img_size), \n",
    "                                             shuffle = True, class_mode = 'binary', seed = 42) \n",
    "\n",
    "# generate testing data from testing path with batch size and target size specified\n",
    "test_data = test_datagen.flow_from_directory(testing_path, batch_size = batch_size, target_size = (img_size, img_size),\n",
    "                                             shuffle = True, class_mode = 'binary', seed = 42)\n",
    "\n",
    "# print class indices for binary classification\n",
    "print(train_data.class_indices)\n",
    "print(val_data.class_indices)\n",
    "print(test_data.class_indices)\n",
    "\n",
    "\n",
    "# get the first batch of training data\n",
    "batchX, batchy = train_data.next()\n",
    "# print the shape of training batch and label batch\n",
    "print('train_batch.shape:', batchX.shape)\n",
    "print('label_batch.shape', batchy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchX[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Model 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_shape=(112, 112, 3)):\n",
    "    #weight initialization\n",
    "    init = RandomNormal(mean = 0.0, stddev = 0.02)\n",
    "    \n",
    "    # convolutional block\n",
    "    def conv_block(input_layer, filter_size, stride):\n",
    "        x = Conv2D(filter_size, kernel_size = (3,3), padding='same', \n",
    "                   strides=stride, kernel_initializer = init)(input_layer)\n",
    "        x = BatchNormalization(momentum = 0.9)(x)\n",
    "        x = LeakyReLU(alpha = 0.2)(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        return x\n",
    "    \n",
    "    # input image\n",
    "    input_img = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(32, kernel_size = (3, 3), strides = (1, 1), padding='same', \n",
    "               kernel_initializer = init)(input_img)\n",
    "    x = BatchNormalization(momentum = 0.9)(x)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # downsample to 56 x 56 x 64\n",
    "    x = conv_block(x, 64, (2, 2))\n",
    "    # downsample to 28 x 28 x 128\n",
    "    x = conv_block(x, 128, (2, 2))\n",
    "#     x = MaxPooling2D(pool_size = (2, 2), strides = (2, 2))(x)\n",
    "#     x = BatchNormalization(momentum = 0.9)(x)\n",
    "#     x = LeakyReLU(alpha = 0.2)(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "    # downsample to 14 x 14 x 256\n",
    "    x = conv_block(x, 256, (2, 2))\n",
    "    # downsample to 7 x 7 x 512\n",
    "    x = conv_block(x, 512, (2, 2))\n",
    "#     x = MaxPooling2D(pool_size = (2, 2), strides = (2, 2))(x)\n",
    "#     x = BatchNormalization(momentum = 0.9)(x)\n",
    "#     x = LeakyReLU(alpha = 0.2)(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "    \n",
    "    # flatten layer\n",
    "    features = Flatten()(x)\n",
    "\n",
    "    # binary classifier, image fake or real\n",
    "    fake = Dense(1, activation='sigmoid', name='generation')(features)\n",
    "\n",
    "    # multi-class classifier, image digit class\n",
    "    aux = Dense(3, activation='softmax', name='auxiliary')(features)\n",
    "\n",
    "    model = Model(inputs = input_img,  outputs = [fake, aux])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 112, 112, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 112, 112, 32  896         ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 112, 112, 32  128        ['conv2d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 112, 112, 32  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 112, 112, 32  0           ['leaky_re_lu_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 64)   18496       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 56, 56, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 56, 56, 64)   0           ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 28, 28, 128)  73856       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 28, 28, 128)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 28, 28, 128)  0           ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 14, 14, 256)  295168      ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 14, 14, 256)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 14, 14, 256)  0           ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 7, 7, 512)    1180160     ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 7, 7, 512)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 7, 7, 512)    0           ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 25088)        0           ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " generation (Dense)             (None, 1)            25089       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " auxiliary (Dense)              (None, 2)            50178       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,647,811\n",
      "Trainable params: 1,645,827\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giorgio/miniconda3/envs/DL38/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "d = discriminator(input_shape=(112, 112, 3))\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    inputs = Input(shape=(112, 112, 1))\n",
    "    leaky = tf.keras.layers.LeakyReLU(0.2)\n",
    "\n",
    "    conv1 = Conv2D(32, 3, activation=leaky, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Dropout(0.2)(conv1)\n",
    "\n",
    "    conv1 = Conv2D(32, 3, activation=leaky, padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, 3, activation=leaky, padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)\n",
    "\n",
    "    conv2 = Conv2D(64, 3, activation=leaky, padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, 3, activation=leaky, padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "\n",
    "    conv3 = Conv2D(128, 3, activation=leaky, padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, 3, activation=leaky, padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "\n",
    "    conv4 = Conv2D(256, 3, activation=leaky, padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, 3, activation=leaky, padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Dropout(0.2)(conv5)\n",
    "\n",
    "    conv5 = Conv2D(512, 3, activation=leaky, padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    gap1 = GlobalAveragePooling2D()(drop5)\n",
    "    fc1 = Dense(128)(gap1)\n",
    "            \n",
    "    output_disc = Dense(1, activation=\"linear\")(fc1)\n",
    "    output_class = Dense(3, activation=\"linear\")(fc1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[output_disc, output_class])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 112, 112, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 112, 112, 32  320         ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 112, 112, 32  0           ['conv2d_10[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 112, 112, 32  9248        ['dropout_10[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 56, 56, 32)   0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 56, 56, 64)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 56, 56, 64)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 56, 56, 64)   36928       ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 64)  0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 28, 28, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 28, 28, 128)  0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 28, 28, 128)  147584      ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 128)  0          ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 14, 14, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 14, 14, 256)  0           ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 14, 14, 256)  590080      ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 256)   0           ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 7, 7, 512)    1180160     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 7, 7, 512)    0           ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 7, 7, 512)    2359808     ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 7, 7, 512)    0           ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['dropout_15[0][0]']             \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          65664       ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            129         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3)            387         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,777,828\n",
      "Trainable params: 4,777,828\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_discriminator().summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(latent_dim = 100, n_classes = 3):\n",
    "    init = RandomNormal(mean = 0.0, stddev = 0.02)\n",
    "  \n",
    "    # Input 1: class label input\n",
    "    label_input = Input(shape = (1,))\n",
    "    print(label_input.shape)\n",
    "    y = Embedding(n_classes, 100)(label_input)\n",
    "    print('Embedding Layer: ', y.shape)\n",
    "    n_nodes = 7 * 7\n",
    "    y = Dense(n_nodes, kernel_initializer = init)(y)\n",
    "    print('Dense 1: ', y.shape)\n",
    "    y = Reshape((7, 7 ,1))(y)\n",
    "    print('reshape(final y shape): ', y.shape)\n",
    "\n",
    "    # Input 2: generator noise input\n",
    "    generator_input = Input(shape = (latent_dim,))\n",
    "    n_nodes = 1024 * 7 * 7\n",
    "    gen = Dense(n_nodes, kernel_initializer = init)(generator_input)\n",
    "    gen = Activation('relu')(gen)\n",
    "    gen = Reshape((7, 7, 1024))(gen)\n",
    "    print('Generator noise input: ', gen.shape)\n",
    "    # Concatenate both the inputs\n",
    "    merge = Concatenate()([gen, y])\n",
    "    print('Concatenate(generator noise input and y: ', merge.shape)\n",
    "\n",
    "    # (None, 7, 7, 1024) --> (None, 14, 14, 512)\n",
    "    gen = Conv2DTranspose(512, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", kernel_initializer = init)(merge)\n",
    "    gen = BatchNormalization(momentum = 0.9)(gen)\n",
    "    gen = Activation(\"relu\")(gen)\n",
    "    print(\"(None, 7, 7, 1024) -> (None, 14, 14, 512): \", gen.shape)\n",
    "\n",
    "    # (None, 14, 14, 512)  --> (None, 28, 28, 256)\n",
    "    gen = Conv2DTranspose(256, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", kernel_initializer = init)(gen)\n",
    "    gen = BatchNormalization(momentum = 0.9)(gen)\n",
    "    gen = Activation(\"relu\")(gen)\n",
    "    print('(None, 14, 14, 512) -> (None, 28, 28, 256): ', gen.shape)\n",
    "\n",
    "    # (None, 28, 28, 256) --> (None, 56, 56, 128)\n",
    "    gen = Conv2DTranspose(128, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", kernel_initializer = init)(gen)\n",
    "    gen = BatchNormalization(momentum = 0.9)(gen)\n",
    "    gen = Activation(\"relu\")(gen)\n",
    "    print('(None, 28, 28, 256) -> (None, 56, 56, 128): ', gen.shape)\n",
    "\n",
    "    # (None, 56, 56, 128) --> (None, 112, 112, 3)\n",
    "    gen = Conv2DTranspose(3, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", kernel_initializer = init)(gen)\n",
    "    out_layer = Activation(\"tanh\")(gen)\n",
    "    print(\"(None, 56, 56, 128) -> (None, 112, 112, 3): \", out_layer.shape)\n",
    "    \n",
    "    model = Model(inputs = [generator_input, label_input], outputs = out_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1)\n",
      "Embedding Layer:  (None, 1, 100)\n",
      "Dense 1:  (None, 1, 49)\n",
      "reshape(final y shape):  (None, 7, 7, 1)\n",
      "Generator noise input:  (None, 7, 7, 1024)\n",
      "Concatenate(generator noise input and y:  (None, 7, 7, 1025)\n",
      "(None, 7, 7, 1024) -> (None, 14, 14, 512):  (None, 14, 14, 512)\n",
      "(None, 14, 14, 512) -> (None, 28, 28, 256):  (None, 28, 28, 256)\n",
      "(None, 28, 28, 256) -> (None, 56, 56, 128):  (None, 56, 56, 128)\n",
      "(None, 56, 56, 128) -> (None, 112, 112, 3):  (None, 112, 112, 3)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50176)        5067776     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 100)       300         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 50176)        0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 49)        4949        ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 7, 7, 1024)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 7, 7, 1)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 7, 7, 1025)   0           ['reshape_1[0][0]',              \n",
      "                                                                  'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 14, 14, 512)  13120512   ['concatenate[0][0]']            \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 14, 14, 512)  2048       ['conv2d_transpose[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 14, 14, 512)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 28, 28, 256)  3277056    ['activation_1[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 28, 256)  1024       ['conv2d_transpose_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 28, 256)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 56, 56, 128)  819328     ['activation_2[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 56, 56, 128)  512        ['conv2d_transpose_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 112, 112, 3)  9603       ['activation_3[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 112, 112, 3)  0           ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,303,108\n",
      "Trainable params: 22,301,316\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = generator(latent_dim = 100, n_classes = 3)\n",
    "g.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AC-cGAN model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_lr = 0.0002\n",
    "adam_beta_1 = 0.5\n",
    "\n",
    "def define_gan(latent_dim = 100):\n",
    "    # build the discriminator\n",
    "    dis = discriminator()\n",
    "    dis.summary()\n",
    "    dis.compile(\n",
    "        optimizer=Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    "    )\n",
    "\n",
    "    # build the generator\n",
    "    gen = generator(latent_dim)\n",
    "    gen.summary()\n",
    "    gen.compile(optimizer=Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n",
    "                      loss='binary_crossentropy')\n",
    "\n",
    "    # Inputs\n",
    "    latent = Input(shape=(latent_dim, ), name='latent_noise')\n",
    "    image_class = Input(shape=(1,), name='image_class')\n",
    "    print(image_class.dtype)\n",
    "    # Get a fake image\n",
    "    fake_img = gen([latent, image_class])\n",
    "    print('fake image: ', fake_img.shape)\n",
    "    # Only train generator in combined model\n",
    "    dis.trainable = False\n",
    "    fake, aux = dis(fake_img)\n",
    "    combined = Model(inputs=[latent, image_class],\n",
    "                            outputs=[fake, aux],\n",
    "                            name='ACGAN')\n",
    "\n",
    "    combined.compile(\n",
    "        optimizer=Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    "    )\n",
    "    \n",
    "    combined.summary()\n",
    "    return combined, dis, gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giorgio/miniconda3/envs/DL38/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1)\n",
      "Embedding Layer:  (None, 1, 100)\n",
      "Dense 1:  (None, 1, 49)\n",
      "reshape(final y shape):  (None, 7, 7, 1)\n",
      "Generator noise input:  (None, 7, 7, 1024)\n",
      "Concatenate(generator noise input and y:  (None, 7, 7, 1025)\n",
      "(None, 7, 7, 1024) -> (None, 14, 14, 512):  (None, 14, 14, 512)\n",
      "(None, 14, 14, 512) -> (None, 28, 28, 256):  (None, 28, 28, 256)\n",
      "(None, 28, 28, 256) -> (None, 56, 56, 128):  (None, 56, 56, 128)\n",
      "(None, 56, 56, 128) -> (None, 112, 112, 3):  (None, 112, 112, 3)\n",
      "<dtype: 'float32'>\n",
      "fake image:  (None, 112, 112, 3)\n",
      "Model: \"ACGAN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " latent_noise (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " image_class (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " model_4 (Functional)           (None, 112, 112, 3)  22303108    ['latent_noise[0][0]',           \n",
      "                                                                  'image_class[0][0]']            \n",
      "                                                                                                  \n",
      " model_3 (Functional)           [(None, 1),          1647811     ['model_4[0][0]']                \n",
      "                                 (None, 2)]                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,950,919\n",
      "Trainable params: 22,301,316\n",
      "Non-trainable params: 1,649,603\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_model = define_gan(latent_dim=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AC-cGAN Trainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_smoothing(vector, max_dev = 0.2):\n",
    "        d = max_dev * np.random.rand(vector.shape[0],vector.shape[1])\n",
    "        if vector[0][0] == 0:\n",
    "            return vector + d\n",
    "        else:\n",
    "            return vector - d\n",
    "          \n",
    "valid_o = np.ones((batch_size, 1))\n",
    "fake_o = np.zeros((batch_size, 1))\n",
    "\n",
    "# Function for printing the logs after every epoch\n",
    "\n",
    "def print_logs(metrics_names, train_history, test_history):\n",
    "\n",
    "    print('{0:<22s} | {1:4s} | {2:15s} | {3:5s}'.format(\n",
    "        'component', *metrics_names))\n",
    "    print('-' * 65)\n",
    "\n",
    "    ROW_FMT = '{0:<22s} | {1:<4.2f} | {2:<15.2f} | {3:<5.2f}'\n",
    "    print(ROW_FMT.format('generator (train)',\n",
    "                         *train_history['generator'][-1]))\n",
    "    print(ROW_FMT.format('generator (test)',\n",
    "                         *test_history['generator'][-1]))\n",
    "    print(ROW_FMT.format('discriminator (train)',\n",
    "                         *train_history['discriminator'][-1]))\n",
    "    print(ROW_FMT.format('discriminator (test)',\n",
    "                         *test_history['discriminator'][-1]))\n",
    "\n",
    "# Function to generate a batch of noise and label \n",
    "\n",
    "def generate_batch_noise_and_labels(batch_size, latent_dim, n_classes = 3):\n",
    "\n",
    "    # generate a new batch of noise\n",
    "    noise = np.random.uniform(-1, 1, (batch_size, latent_dim))\n",
    "\n",
    "    # sample some labels\n",
    "    sampled_labels = np.random.randint(0, n_classes, batch_size)\n",
    "\n",
    "    return noise, sampled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 2, 2, 2, 2, 1, 1, 2, 0,\n",
       "       0, 1, 1, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 3, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to generate the loss graph using the saved weights\n",
    "\n",
    "import pandas as pd\n",
    "path = './AC-cGAN/weights/acgan_history.pkl'\n",
    "path.encode('utf-8').strip()\n",
    "hist = pickle.load(open(path, 'rb'))\n",
    "\n",
    "for p in ['train', 'test']:\n",
    "    for g in ['discriminator', 'generator']:\n",
    "        hist[p][g] = pd.DataFrame(hist[p][g], columns=['loss', 'generation_loss', 'auxiliary_loss'])\n",
    "        plt.plot(hist[p][g]['generation_loss'], label='{} ({})'.format(g, p))\n",
    "\n",
    "# get the NE and show as an equilibrium point\n",
    "plt.hlines(-np.log(0.5), 0, hist[p][g]['generation_loss'].shape[0], label='Nash Equilibrium')\n",
    "plt.legend()\n",
    "plt.title(r'$L_s$ (generation loss) per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(r'$L_s$')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 1200\n",
    "batch_size = 36\n",
    "latent_dim = 100\n",
    "\n",
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 19:58:28.400204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-06 19:58:28.402658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-06 19:58:28.402691: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-06 19:58:28.403414: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 19:58:28.404583: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-06 19:58:28.404617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-06 19:58:28.404633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-06 19:58:29.568490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-06 19:58:29.568563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-06 19:58:29.568572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-02-06 19:58:29.568599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-06 19:58:29.568678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/giorgio/miniconda3/envs/DL38/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 112, 112, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 112, 112, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 112, 112, 32  128        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 112, 112, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 112, 112, 32  0           ['leaky_re_lu[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 56, 56, 64)   18496       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 56, 56, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 56, 56, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 56, 56, 64)   0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 128)  73856       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 28, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 28, 28, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 28, 28, 128)  0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 14, 14, 256)  295168      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 14, 14, 256)  1024       ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 14, 14, 256)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 14, 14, 256)  0           ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 7, 7, 512)    1180160     ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 7, 7, 512)   2048        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 7, 7, 512)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 7, 7, 512)    0           ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 25088)        0           ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " generation (Dense)             (None, 1)            25089       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " auxiliary (Dense)              (None, 3)            75267       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,672,900\n",
      "Trainable params: 1,670,916\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n",
      "(None, 1)\n",
      "Embedding Layer:  (None, 1, 100)\n",
      "Dense 1:  (None, 1, 49)\n",
      "reshape(final y shape):  (None, 7, 7, 1)\n",
      "Generator noise input:  (None, 7, 7, 1024)\n",
      "Concatenate(generator noise input and y:  (None, 7, 7, 1025)\n",
      "(None, 7, 7, 1024) -> (None, 14, 14, 512):  (None, 14, 14, 512)\n",
      "(None, 14, 14, 512) -> (None, 28, 28, 256):  (None, 28, 28, 256)\n",
      "(None, 28, 28, 256) -> (None, 56, 56, 128):  (None, 56, 56, 128)\n",
      "(None, 56, 56, 128) -> (None, 112, 112, 3):  (None, 112, 112, 3)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50176)        5067776     ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 100)       300         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 50176)        0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 49)        4949        ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 7, 7, 1024)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 7, 7, 1)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 7, 7, 1025)   0           ['reshape_1[0][0]',              \n",
      "                                                                  'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 14, 14, 512)  13120512   ['concatenate[0][0]']            \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 14, 14, 512)  2048       ['conv2d_transpose[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 14, 14, 512)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 28, 28, 256)  3277056    ['activation_1[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 28, 256)  1024       ['conv2d_transpose_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 28, 256)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 56, 56, 128)  819328     ['activation_2[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 56, 56, 128)  512        ['conv2d_transpose_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 112, 112, 3)  9603       ['activation_3[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 112, 112, 3)  0           ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,303,108\n",
      "Trainable params: 22,301,316\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n",
      "<dtype: 'float32'>\n",
      "fake image:  (None, 112, 112, 3)\n",
      "Model: \"ACGAN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " latent_noise (InputLayer)      [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " image_class (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 112, 112, 3)  22303108    ['latent_noise[0][0]',           \n",
      "                                                                  'image_class[0][0]']            \n",
      "                                                                                                  \n",
      " model (Functional)             [(None, 1),          1672900     ['model_1[0][0]']                \n",
      "                                 (None, 3)]                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,976,008\n",
      "Trainable params: 22,301,316\n",
      "Non-trainable params: 1,674,692\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined, dis, gen = define_gan(latent_dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(valid.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [0]\n",
      " [0]\n",
      " [2]]\n",
      "2/2 [==============================] - 0s 400ms/step\n",
      "36\n",
      "(36, 112, 112, 3)\n",
      "(72, 112, 112, 3)\n",
      "(36, 1)\n",
      "(36, 1)\n",
      "(72, 1)\n",
      "(72, 1)\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[array([[0.46632695],\n",
      "       [0.44227803],\n",
      "       [0.47825062],\n",
      "       [0.47187778],\n",
      "       [0.46730426],\n",
      "       [0.49230516],\n",
      "       [0.44712755],\n",
      "       [0.46967837],\n",
      "       [0.49164385],\n",
      "       [0.45876145],\n",
      "       [0.46461704],\n",
      "       [0.5041681 ],\n",
      "       [0.44422537],\n",
      "       [0.4657744 ],\n",
      "       [0.48983222],\n",
      "       [0.4625748 ],\n",
      "       [0.5186298 ],\n",
      "       [0.4690823 ],\n",
      "       [0.49717858],\n",
      "       [0.48496255],\n",
      "       [0.44700554],\n",
      "       [0.4461117 ],\n",
      "       [0.485333  ],\n",
      "       [0.46369112],\n",
      "       [0.46807384],\n",
      "       [0.5257085 ],\n",
      "       [0.47300136],\n",
      "       [0.47402355],\n",
      "       [0.49519083],\n",
      "       [0.4526591 ],\n",
      "       [0.48429024],\n",
      "       [0.4707228 ],\n",
      "       [0.4920724 ],\n",
      "       [0.45337746],\n",
      "       [0.4745044 ],\n",
      "       [0.4589809 ],\n",
      "       [0.50000334],\n",
      "       [0.49999928],\n",
      "       [0.49999082],\n",
      "       [0.49999022],\n",
      "       [0.49999332],\n",
      "       [0.49999142],\n",
      "       [0.49999672],\n",
      "       [0.4999975 ],\n",
      "       [0.5000007 ],\n",
      "       [0.5000076 ],\n",
      "       [0.49999928],\n",
      "       [0.49999702],\n",
      "       [0.50000685],\n",
      "       [0.4999891 ],\n",
      "       [0.5000028 ],\n",
      "       [0.4999982 ],\n",
      "       [0.5000015 ],\n",
      "       [0.5000039 ],\n",
      "       [0.49998367],\n",
      "       [0.49999213],\n",
      "       [0.50000477],\n",
      "       [0.50000244],\n",
      "       [0.50000834],\n",
      "       [0.49999464],\n",
      "       [0.50000066],\n",
      "       [0.500004  ],\n",
      "       [0.49999118],\n",
      "       [0.49999857],\n",
      "       [0.49999613],\n",
      "       [0.49998754],\n",
      "       [0.49998486],\n",
      "       [0.49999297],\n",
      "       [0.49999297],\n",
      "       [0.49999774],\n",
      "       [0.49999523],\n",
      "       [0.4999987 ]], dtype=float32), array([[0.33816552, 0.27353776, 0.38829675],\n",
      "       [0.33849484, 0.28846666, 0.37303844],\n",
      "       [0.31375584, 0.30767536, 0.37856874],\n",
      "       [0.32643303, 0.31217188, 0.36139506],\n",
      "       [0.33386597, 0.32399586, 0.3421382 ],\n",
      "       [0.3219006 , 0.26859728, 0.40950215],\n",
      "       [0.32107955, 0.2814061 , 0.3975143 ],\n",
      "       [0.3364361 , 0.29259288, 0.370971  ],\n",
      "       [0.29440233, 0.33363077, 0.37196687],\n",
      "       [0.31666014, 0.3248902 , 0.3584497 ],\n",
      "       [0.35054493, 0.31420133, 0.3352538 ],\n",
      "       [0.31703898, 0.29879496, 0.38416603],\n",
      "       [0.31631425, 0.29755494, 0.38613084],\n",
      "       [0.33367682, 0.27568814, 0.39063504],\n",
      "       [0.30188534, 0.30868757, 0.38942707],\n",
      "       [0.33777037, 0.3127162 , 0.3495134 ],\n",
      "       [0.34320453, 0.3184154 , 0.33838   ],\n",
      "       [0.31062412, 0.28661382, 0.40276206],\n",
      "       [0.3180802 , 0.25238663, 0.42953318],\n",
      "       [0.32723552, 0.3124452 , 0.3603193 ],\n",
      "       [0.3430996 , 0.29923525, 0.3576652 ],\n",
      "       [0.35099888, 0.2563283 , 0.39267278],\n",
      "       [0.32624707, 0.3188075 , 0.35494545],\n",
      "       [0.2762379 , 0.2810409 , 0.44272122],\n",
      "       [0.3528003 , 0.3118103 , 0.33538932],\n",
      "       [0.2756046 , 0.31909016, 0.40530518],\n",
      "       [0.34517738, 0.27266198, 0.38216063],\n",
      "       [0.32122293, 0.2647067 , 0.41407043],\n",
      "       [0.29634556, 0.3086078 , 0.39504662],\n",
      "       [0.37631634, 0.2626533 , 0.36103034],\n",
      "       [0.30353796, 0.3076016 , 0.38886043],\n",
      "       [0.34775537, 0.26723337, 0.3850113 ],\n",
      "       [0.301735  , 0.29970968, 0.39855528],\n",
      "       [0.3290624 , 0.28199118, 0.38894638],\n",
      "       [0.32164046, 0.30322403, 0.3751355 ],\n",
      "       [0.3444701 , 0.26767123, 0.38785866],\n",
      "       [0.33333945, 0.33333343, 0.33332714],\n",
      "       [0.33334056, 0.33332092, 0.33333847],\n",
      "       [0.33333364, 0.33332512, 0.33334127],\n",
      "       [0.33332828, 0.3333265 , 0.3333452 ],\n",
      "       [0.33332714, 0.33333147, 0.33334136],\n",
      "       [0.33332825, 0.3333253 , 0.33334646],\n",
      "       [0.33333036, 0.33332413, 0.33334553],\n",
      "       [0.3333304 , 0.33332205, 0.33334756],\n",
      "       [0.3333225 , 0.33332855, 0.33334896],\n",
      "       [0.3333224 , 0.33332768, 0.33334997],\n",
      "       [0.33332697, 0.3333268 , 0.33334622],\n",
      "       [0.33332524, 0.33333215, 0.33334267],\n",
      "       [0.33333832, 0.3333258 , 0.33333588],\n",
      "       [0.33332136, 0.3333212 , 0.33335742],\n",
      "       [0.3333297 , 0.33332852, 0.33334178],\n",
      "       [0.33332425, 0.333322  , 0.3333538 ],\n",
      "       [0.33332363, 0.33333272, 0.33334363],\n",
      "       [0.3333262 , 0.33333418, 0.33333963],\n",
      "       [0.33333513, 0.3333202 , 0.33334473],\n",
      "       [0.33333287, 0.33331156, 0.33335558],\n",
      "       [0.33332697, 0.33333698, 0.33333606],\n",
      "       [0.3333228 , 0.33333415, 0.33334303],\n",
      "       [0.33332124, 0.3333415 , 0.33333722],\n",
      "       [0.33332092, 0.33333176, 0.33334735],\n",
      "       [0.33331928, 0.33333755, 0.33334318],\n",
      "       [0.33333153, 0.33332008, 0.33334842],\n",
      "       [0.3333337 , 0.33332175, 0.33334452],\n",
      "       [0.3333317 , 0.33333057, 0.33333772],\n",
      "       [0.3333347 , 0.3333314 , 0.33333388],\n",
      "       [0.33333462, 0.33332697, 0.3333384 ],\n",
      "       [0.3333286 , 0.33332285, 0.33334854],\n",
      "       [0.33332554, 0.33333635, 0.3333381 ],\n",
      "       [0.33332708, 0.3333248 , 0.3333481 ],\n",
      "       [0.33332038, 0.33333585, 0.33334383],\n",
      "       [0.33333158, 0.33332044, 0.33334798],\n",
      "       [0.33331448, 0.33333775, 0.3333478 ]], dtype=float32)]\n",
      "WARNING:tensorflow:6 out of the last 17 calls to <function Model.make_train_function.<locals>.train_function at 0x7ff2595ba280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[2.7993955612182617, 0.9094502329826355, 1.889945387840271]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 19:51:54.334567: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_10/dropout_25/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    }
   ],
   "source": [
    "noise, sampled_labels = generate_batch_noise_and_labels(batch_size, latent_dim, n_classes = 3)\n",
    "print(sampled_labels.reshape((-1, 1))[1:5])\n",
    "generated_images = gen.predict([noise, sampled_labels.reshape((-1, 1))], verbose=1)\n",
    "#print(generated_images[1])\n",
    "print(len(generated_images))\n",
    "print(generated_images.shape)\n",
    "X = np.concatenate((batchX, generated_images))\n",
    "print(X.shape)\n",
    "\n",
    "valid = label_smoothing(vector = valid_o, max_dev = 0.2)\n",
    "#print(valid)\n",
    "print(valid.shape)\n",
    "fake = label_smoothing(vector = fake_o, max_dev = 0.2)\n",
    "print(fake.shape)\n",
    "\n",
    "y = np.concatenate((valid, fake), axis = 0)\n",
    "print(y.shape)\n",
    "aux_y = np.concatenate((batchy, sampled_labels), axis=0)\n",
    "aux_y = np.reshape(aux_y, (-1, 1))\n",
    "print(aux_y.shape)\n",
    "print(dis.predict(X))\n",
    "print(dis.train_on_batch(X, [y, aux_y]))\n",
    "\n",
    "#print(y)\n",
    "#print(aux_y)\n",
    "print(len([y, aux_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(aux_y, (-1, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 35s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 1:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.62 | 1.55            | 0.06 \n",
      "generator (test)       | 0.17 | 0.15            | 0.02 \n",
      "discriminator (train)  | 0.76 | 0.46            | 0.30 \n",
      "discriminator (test)   | 1.43 | 1.07            | 0.36 \n",
      "Epoch 2 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 18s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 2:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.74 | 1.68            | 0.06 \n",
      "generator (test)       | 2.39 | 2.39            | 0.00 \n",
      "discriminator (train)  | 0.79 | 0.50            | 0.28 \n",
      "discriminator (test)   | 2.25 | 1.42            | 0.83 \n",
      "Epoch 3 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 19s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 3:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.73 | 1.69            | 0.04 \n",
      "generator (test)       | 1.64 | 1.64            | 0.00 \n",
      "discriminator (train)  | 0.78 | 0.49            | 0.30 \n",
      "discriminator (test)   | 0.57 | 0.20            | 0.37 \n",
      "Epoch 4 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 18s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 4:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.95 | 1.91            | 0.04 \n",
      "generator (test)       | 0.31 | 0.29            | 0.02 \n",
      "discriminator (train)  | 0.75 | 0.44            | 0.31 \n",
      "discriminator (test)   | 1.07 | 0.80            | 0.28 \n",
      "Epoch 5 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 19s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 5:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.83 | 1.76            | 0.07 \n",
      "generator (test)       | 0.88 | 0.72            | 0.16 \n",
      "discriminator (train)  | 0.79 | 0.50            | 0.29 \n",
      "discriminator (test)   | 1.05 | 0.62            | 0.43 \n",
      "Epoch 6 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 6:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 2.38 | 2.33            | 0.05 \n",
      "generator (test)       | 1.33 | 1.33            | 0.00 \n",
      "discriminator (train)  | 0.82 | 0.50            | 0.33 \n",
      "discriminator (test)   | 0.79 | 0.16            | 0.64 \n",
      "Epoch 7 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 18s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 7:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.60 | 1.57            | 0.04 \n",
      "generator (test)       | 0.63 | 0.62            | 0.01 \n",
      "discriminator (train)  | 0.77 | 0.45            | 0.32 \n",
      "discriminator (test)   | 0.98 | 0.61            | 0.37 \n",
      "Epoch 8 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 18s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 8:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.10 | 1.02            | 0.07 \n",
      "generator (test)       | 1.23 | 1.20            | 0.03 \n",
      "discriminator (train)  | 0.82 | 0.55            | 0.27 \n",
      "discriminator (test)   | 0.73 | 0.42            | 0.30 \n",
      "Epoch 9 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 19s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 9:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.63 | 1.58            | 0.05 \n",
      "generator (test)       | 4.13 | 4.12            | 0.01 \n",
      "discriminator (train)  | 0.83 | 0.54            | 0.29 \n",
      "discriminator (test)   | 2.00 | 1.64            | 0.36 \n",
      "Epoch 10 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 10:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.68 | 1.65            | 0.03 \n",
      "generator (test)       | 1.79 | 1.78            | 0.01 \n",
      "discriminator (train)  | 0.74 | 0.43            | 0.31 \n",
      "discriminator (test)   | 0.65 | 0.11            | 0.54 \n",
      "Epoch 11 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 22s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 11:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.61 | 1.56            | 0.05 \n",
      "generator (test)       | 2.59 | 2.54            | 0.05 \n",
      "discriminator (train)  | 0.76 | 0.48            | 0.28 \n",
      "discriminator (test)   | 0.96 | 0.60            | 0.36 \n",
      "Epoch 12 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 23s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 12:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.03 | 0.98            | 0.05 \n",
      "generator (test)       | 0.45 | 0.37            | 0.08 \n",
      "discriminator (train)  | 0.78 | 0.50            | 0.28 \n",
      "discriminator (test)   | 1.08 | 0.70            | 0.38 \n",
      "Epoch 13 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 23s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 18s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 18s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 13:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 2.45 | 2.39            | 0.06 \n",
      "generator (test)       | 3.11 | 3.11            | 0.01 \n",
      "discriminator (train)  | 0.84 | 0.52            | 0.32 \n",
      "discriminator (test)   | 1.17 | 0.48            | 0.69 \n",
      "Epoch 14 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 20s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 14:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 0.62 | 0.57            | 0.04 \n",
      "generator (test)       | 1.06 | 1.04            | 0.02 \n",
      "discriminator (train)  | 0.79 | 0.46            | 0.33 \n",
      "discriminator (test)   | 0.55 | 0.27            | 0.28 \n",
      "Epoch 15 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 21s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 15:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 2.50 | 2.46            | 0.05 \n",
      "generator (test)       | 6.03 | 6.03            | 0.00 \n",
      "discriminator (train)  | 0.77 | 0.50            | 0.27 \n",
      "discriminator (test)   | 2.03 | 1.80            | 0.23 \n",
      "Epoch 16 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 19s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 16:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 0.75 | 0.72            | 0.03 \n",
      "generator (test)       | 1.96 | 1.94            | 0.01 \n",
      "discriminator (train)  | 0.75 | 0.48            | 0.27 \n",
      "discriminator (test)   | 1.07 | 0.78            | 0.29 \n",
      "Epoch 17 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 22s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 18s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 17:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.12 | 1.06            | 0.06 \n",
      "generator (test)       | 1.24 | 1.19            | 0.05 \n",
      "discriminator (train)  | 0.76 | 0.48            | 0.27 \n",
      "discriminator (test)   | 0.65 | 0.36            | 0.29 \n",
      "Epoch 18 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 22s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 18:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 1.96 | 1.86            | 0.10 \n",
      "generator (test)       | 8.71 | 8.71            | 0.00 \n",
      "discriminator (train)  | 0.82 | 0.53            | 0.29 \n",
      "discriminator (test)   | 2.57 | 2.30            | 0.27 \n",
      "Epoch 19 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 19s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 19s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 18s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 17s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 16s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "33/37 [=========================>....] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "34/37 [==========================>...] - ETA: 1s36\n",
      "36\n",
      "72\n",
      "35/37 [===========================>..] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "36/37 [============================>.] - ETA: 0s36\n",
      "36\n",
      "72\n",
      "\n",
      "Testing for epoch 19:\n",
      "component              | loss | generation_loss | auxiliary_loss\n",
      "-----------------------------------------------------------------\n",
      "generator (train)      | 2.62 | 2.57            | 0.05 \n",
      "generator (test)       | 5.82 | 5.81            | 0.00 \n",
      "discriminator (train)  | 0.74 | 0.41            | 0.33 \n",
      "discriminator (test)   | 1.01 | 0.32            | 0.70 \n",
      "Epoch 20 of 1200\n",
      " 0/37 [..............................] - ETA: 0s36\n",
      "36\n",
      "72\n",
      " 1/37 [..............................] - ETA: 19s36\n",
      "36\n",
      "72\n",
      " 2/37 [>.............................] - ETA: 15s36\n",
      "36\n",
      "72\n",
      " 3/37 [=>............................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 4/37 [==>...........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 5/37 [===>..........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 6/37 [===>..........................] - ETA: 14s36\n",
      "36\n",
      "72\n",
      " 7/37 [====>.........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 8/37 [=====>........................] - ETA: 13s36\n",
      "36\n",
      "72\n",
      " 9/37 [======>.......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "10/37 [=======>......................] - ETA: 12s36\n",
      "36\n",
      "72\n",
      "11/37 [=======>......................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "12/37 [========>.....................] - ETA: 11s36\n",
      "36\n",
      "72\n",
      "13/37 [=========>....................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "14/37 [==========>...................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "15/37 [===========>..................] - ETA: 10s36\n",
      "36\n",
      "72\n",
      "16/37 [===========>..................] - ETA: 9s 36\n",
      "36\n",
      "72\n",
      "17/37 [============>.................] - ETA: 9s36\n",
      "36\n",
      "72\n",
      "18/37 [=============>................] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "19/37 [==============>...............] - ETA: 8s36\n",
      "36\n",
      "72\n",
      "20/37 [===============>..............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "21/37 [================>.............] - ETA: 7s36\n",
      "36\n",
      "72\n",
      "22/37 [================>.............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "23/37 [=================>............] - ETA: 6s36\n",
      "36\n",
      "72\n",
      "24/37 [==================>...........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "25/37 [===================>..........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "26/37 [====================>.........] - ETA: 5s36\n",
      "36\n",
      "72\n",
      "27/37 [====================>.........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "28/37 [=====================>........] - ETA: 4s36\n",
      "36\n",
      "72\n",
      "29/37 [======================>.......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "30/37 [=======================>......] - ETA: 3s36\n",
      "36\n",
      "72\n",
      "31/37 [========================>.....] - ETA: 2s36\n",
      "36\n",
      "72\n",
      "32/37 [========================>.....] - ETA: 2s36\n",
      "5\n",
      "41\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 41\n  y sizes: 72, 41\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m aux_y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((label_batch, sampled_labels), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39m#print(\"t7\")\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m#print(dis.train_on_batch(X, [y, aux_y]))\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m#print(\"t7.5\")\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m epoch_disc_loss\u001b[39m.\u001b[39mappend(dis\u001b[39m.\u001b[39;49mtrain_on_batch(X, [y, aux_y]))\n\u001b[1;32m     36\u001b[0m \u001b[39m#print(\"t8\")\u001b[39;00m\n\u001b[1;32m     37\u001b[0m noise, sampled_labels \u001b[39m=\u001b[39m generate_batch_noise_and_labels(\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m batch_size, latent_dim)\n",
      "File \u001b[0;32m~/miniconda3/envs/DL38/lib/python3.8/site-packages/keras/engine/training.py:2474\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_metrics()\n\u001b[1;32m   2471\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m   2472\u001b[0m     \u001b[39mself\u001b[39m\n\u001b[1;32m   2473\u001b[0m ):\n\u001b[0;32m-> 2474\u001b[0m     iterator \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49msingle_batch_iterator(\n\u001b[1;32m   2475\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2476\u001b[0m     )\n\u001b[1;32m   2477\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[1;32m   2478\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n",
      "File \u001b[0;32m~/miniconda3/envs/DL38/lib/python3.8/site-packages/keras/engine/data_adapter.py:1828\u001b[0m, in \u001b[0;36msingle_batch_iterator\u001b[0;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1826\u001b[0m     data \u001b[39m=\u001b[39m (x, y, sample_weight)\n\u001b[0;32m-> 1828\u001b[0m _check_data_cardinality(data)\n\u001b[1;32m   1829\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensors(data)\n\u001b[1;32m   1830\u001b[0m \u001b[39mif\u001b[39;00m class_weight:\n",
      "File \u001b[0;32m~/miniconda3/envs/DL38/lib/python3.8/site-packages/keras/engine/data_adapter.py:1848\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1842\u001b[0m         label,\n\u001b[1;32m   1843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m   1844\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1845\u001b[0m         ),\n\u001b[1;32m   1846\u001b[0m     )\n\u001b[1;32m   1847\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1848\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 41\n  y sizes: 72, 41\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epochs):\n",
    "    print('Epoch {} of {}'.format(epoch + 1, nb_epochs))\n",
    "\n",
    "    nb_batches = int(1332/batch_size)\n",
    "    progress_bar = Progbar(target=nb_batches)\n",
    "\n",
    "    epoch_gen_loss = []\n",
    "    epoch_disc_loss = []\n",
    "    gen_test_loss = []\n",
    "    disc_test_loss = []\n",
    "\n",
    "    for index, (image_batch, label_batch) in zip(range(nb_batches), train_data):\n",
    "        #print(\"t1\")\n",
    "        image_batch = image_batch * (1. / 127.5) - 1\n",
    "\n",
    "        progress_bar.update(index)\n",
    "        #print(\"t2\")\n",
    "        noise, sampled_labels = generate_batch_noise_and_labels(batch_size, latent_dim)\n",
    "        #print(\"t3\")\n",
    "        generated_images = gen.predict([noise, sampled_labels.reshape((-1, 1))],  verbose=0)\n",
    "        #print(\"t4\")\n",
    "        print(len(generated_images))\n",
    "        print(len(image_batch))\n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        print(len(X))\n",
    "        #print(\"t5\")\n",
    "        valid = label_smoothing(vector = valid_o, max_dev = 0.2)\n",
    "        fake = label_smoothing(vector = fake_o, max_dev = 0.2)\n",
    "        #print(\"t6\")\n",
    "        y = np.concatenate((valid, fake), axis = 0)\n",
    "        aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n",
    "        #print(\"t7\")\n",
    "        #print(dis.train_on_batch(X, [y, aux_y]))\n",
    "        #print(\"t7.5\")\n",
    "        epoch_disc_loss.append(dis.train_on_batch(X, [y, aux_y]))\n",
    "        #print(\"t8\")\n",
    "        noise, sampled_labels = generate_batch_noise_and_labels(2 * batch_size, latent_dim)\n",
    "                \n",
    "        trick = np.ones(2 * batch_size)\n",
    "        #print(\"t5\")\n",
    "        epoch_gen_loss.append(combined.train_on_batch(\n",
    "            [noise, sampled_labels.reshape((-1, 1))], [trick, sampled_labels]))\n",
    "        #print(\"t6\")\n",
    "        \n",
    "    for test_image_batch, test_label_batch in test_data:\n",
    "                \n",
    "        print('\\nTesting for epoch {}:'.format(epoch + 1))\n",
    "\n",
    "        test_image_batch = test_image_batch * (1. / 127.5) - 1\n",
    "\n",
    "        nb_train = test_image_batch.shape[0]\n",
    "        #nb_test = test_label_batch\n",
    "\n",
    "        noise, sampled_labels = generate_batch_noise_and_labels(nb_train, latent_dim)\n",
    "\n",
    "        generated_images = gen.predict(\n",
    "            [noise, sampled_labels.reshape((-1, 1))], verbose=False\n",
    "        )  \n",
    "            \n",
    "        X = np.concatenate((test_image_batch, generated_images))\n",
    "        y = np.array([1] * nb_train + [0] * nb_train)\n",
    "        aux_y = np.concatenate((test_label_batch, sampled_labels), axis=0)\n",
    "        \n",
    "        #print('1')\n",
    "        \n",
    "        test_discriminator_loss = dis.evaluate(X, [y, aux_y], verbose = False)\n",
    "\n",
    "        #print('2')\n",
    "        \n",
    "        disc_test_loss.append(test_discriminator_loss)\n",
    "\n",
    "        noise, sampled_labels = generate_batch_noise_and_labels(2 * nb_train, latent_dim)\n",
    "\n",
    "\n",
    "        trick = np.ones(2 * nb_train)\n",
    "\n",
    "        test_generator_loss = combined.evaluate(\n",
    "            [noise, sampled_labels.reshape((-1, 1))],\n",
    "            [trick, sampled_labels], verbose = False\n",
    "        )\n",
    "\n",
    "        gen_test_loss.append(test_generator_loss)\n",
    "\n",
    "        break\n",
    "\n",
    "    discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n",
    "\n",
    "    generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n",
    "\n",
    "    generator_test_loss = np.mean(np.array(gen_test_loss), axis=0)\n",
    "\n",
    "    discriminator_test_loss = np.mean(np.array(disc_test_loss), axis=0)\n",
    "\n",
    "    train_history['generator'].append(generator_train_loss)\n",
    "    train_history['discriminator'].append(discriminator_train_loss)\n",
    "\n",
    "    test_history['generator'].append(generator_test_loss)\n",
    "    test_history['discriminator'].append(discriminator_test_loss)\n",
    "\n",
    "    print_logs(dis.metrics_names, train_history, test_history)\n",
    "\n",
    "    # gen.save_weights(\n",
    "    #     './AC-cGAN/parameters/params_generator_epoch_{0:03d}.hdf5'.format(epoch), True)\n",
    "    # dis.save_weights(\n",
    "    #     './AC-cGAN/parameters/params_discriminator_epoch_{0:03d}.hdf5'.format(epoch), True)\n",
    "\n",
    "pickle.dump({'train': train_history, 'test':test_history},\n",
    "            open('./AC-cGAN/weights/acgan_history.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1)\n",
      "Embedding Layer:  (None, 1, 100)\n",
      "Dense 1:  (None, 1, 49)\n",
      "reshape(final y shape):  (None, 7, 7, 1)\n",
      "Generator noise input:  (None, 7, 7, 1024)\n",
      "Concatenate(generator noise input and y:  (None, 7, 7, 1025)\n",
      "(None, 7, 7, 1024) -> (None, 14, 14, 512):  (None, 14, 14, 512)\n",
      "(None, 14, 14, 512) -> (None, 28, 28, 256):  (None, 28, 28, 256)\n",
      "(None, 28, 28, 256) -> (None, 56, 56, 128):  (None, 56, 56, 128)\n",
      "(None, 56, 56, 128) -> (None, 112, 112, 3):  (None, 112, 112, 3)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 50176)        5067776     ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 100)       300         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 50176)        0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1, 49)        4949        ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 7, 7, 1024)   0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 7, 7, 1)      0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 7, 7, 1025)   0           ['reshape_3[0][0]',              \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 14, 14, 512)  13120512   ['concatenate_1[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 14, 14, 512)  2048       ['conv2d_transpose_4[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 14, 14, 512)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 28, 28, 256)  3277056    ['activation_6[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 28, 28, 256)  1024       ['conv2d_transpose_5[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 28, 28, 256)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 56, 56, 128)  819328     ['activation_7[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 56, 56, 128)  512        ['conv2d_transpose_6[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 112, 112, 3)  9603       ['activation_8[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 112, 112, 3)  0           ['conv2d_transpose_7[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,303,108\n",
      "Trainable params: 22,301,316\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giorgio/miniconda3/envs/DL38/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "g_test = generator(latent_dim = 100, n_classes = 3)\n",
    "g_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "36\n",
      "(112, 112, 3)\n"
     ]
    }
   ],
   "source": [
    "adam_lr = 0.0002\n",
    "adam_beta_1 = 0.5\n",
    "nb_epochs = 1200\n",
    "batch_size = 36\n",
    "latent_dim = 100\n",
    "\n",
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)\n",
    "\n",
    "g.compile(optimizer=Adam(learning_rate=adam_lr, beta_1=adam_beta_1),\n",
    "                      loss='binary_crossentropy')\n",
    "\n",
    "noise, sampled_labels = generate_batch_noise_and_labels(batch_size, latent_dim)\n",
    "print(len(noise))\n",
    "print(len(sampled_labels))\n",
    "generated_images = g.predict([noise, sampled_labels.reshape((-1, 1))], verbose=0)\n",
    "print(generated_images[1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60b8044749a6405f667610107d9735b0f1de9c6c5be21049e3f3bfd7f01211da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
